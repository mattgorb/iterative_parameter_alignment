nohup python -u mnist_model_merge.py --epochs=1 --gpu=3 --lr=0.01> ~/out/97.txt 2>&1 &
nohup python -u mnist_model_merge.py --epochs=20000 --baseline=True --gpu=4  --lr=0.01> ~/out/98.txt 2>&1 &



#FIRST
nohup python -u mnist_double.py --graphs=True > ~/iwa/mnist_double.txt 2>&1 &
nohup python -u mnist_single.py --graphs=True > ~/iwa/mnist_single.txt 2>&1 &
nohup python -u mnist_double_cnn.py --gpu=1> ~/iwa/mnist_double_cnn.txt 2>&1 &
nohup python -u mnist_double_cnn.py --gpu=1 --baseline=True --epochs=250> ~/iwa/mnist_double_cnn_baseline.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=2 --baseline=True --epochs=250 > ~/iwa/cifar10_baseline.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=3 --align_loss='se'> ~/iwa/cifar10_se.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=4 --align_loss='ae'> ~/iwa/cifar10_ae.txt 2>&1 &


SECOND
1.  mnist_double with and without kn_init
2.  mnist double cnn with and without kn_init
3.  cifar10 with and without kn_init, ae, transform, without transform

nohup python -u mnist_double.py --gpu=1 --kn_init=True> ~/iwa/mnist_double_kn_init.txt 2>&1 & #0.065 test loss after 10,000
nohup python -u mnist_double.py --gpu=1> ~/iwa/mnist_double_no_kn_init.txt 2>&1 & #0.066 test loss after 10,000 epochs
nohup python -u mnist_double_cnn.py --gpu=2 --kn_init=True> ~/iwa/mnist_double_cnn_kn_init.txt 2>&1 & #0.034 test loss after 1,300 epochs
nohup python -u mnist_double_cnn.py --gpu=2> ~/iwa/mnist_double_cnn_no_kn_init.txt 2>&1 & #0.034 after 2,000 epochs
nohup python -u cifar10_double.py --gpu=3 --align_loss='ae'> ~/iwa/cifar10_ae_no_kn.txt 2>&1 & #72% after 15,000 epochs
nohup python -u cifar10_double.py --gpu=4 --align_loss='ae' --kn_init=True > ~/iwa/cifar10_ae_kn_init.txt 2>&1 & #68% after 15,000 epochs
nohup python -u cifar10_double.py --gpu=5 --align_loss='ae' --data_transform=True> ~/iwa/cifar10_ae_no_kn_data_transform.txt 2>&1 & #82.6 after 11,000 epochs
nohup python -u cifar10_double.py --gpu=6 --align_loss='ae' --kn_init=True --data_transform=True > ~/iwa/cifar10_ae_kn_init_data_transform.txt 2>&1 & # 83% after 11,000 epochs






THIRD
nohup python -u mnist_double.py --gpu=1 --kn_init=True --weight_align_factor=10 > ~/iwa/mnist_double_kn_init_waf_10.txt 2>&1 &
nohup python -u mnist_double_cnn.py --gpu=2 --kn_init=True --weight_align_factor=10> ~/iwa/mnist_double_cnn_kn_init_waf_10.txt 2>&1 &

nohup python -u mnist_double.py --gpu=1 --kn_init=True --weight_align_factor=1 > ~/iwa/mnist_double_kn_init_waf_1.txt 2>&1 &
nohup python -u mnist_double.py --gpu=1 --weight_align_factor=1 > ~/iwa/mnist_double_no_kn_init_waf_1.txt 2>&1 &

nohup python -u mnist_double_cnn.py --gpu=5 --kn_init=True --weight_align_factor=1 > ~/iwa/mnist_double_cnn_kn_init_waf_1.txt 2>&1 & #0.039 after 96 epochs
nohup python -u mnist_double_cnn.py --gpu=5 --weight_align_factor=1 > ~/iwa/mnist_double_cnn_no_kn_init_waf_1.txt 2>&1 &

TAKEAWAYS:
MNIST_CNN works with factor of 1.  Testing with CIFAR10 now.  linear mlp needs a factor of 10.



FOURTH
#BAD
nohup python -u cifar10_double.py --gpu=3 --align_loss='ae' --data_transform=True  --kn_init=True --weight_align_factor=10 --lr=1e-3> ~/iwa/1.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=3 --align_loss='ae' --data_transform=True  --kn_init=True --weight_align_factor=25 --lr=1e-3> ~/iwa/6.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=4 --align_loss='se' --data_transform=True  --kn_init=True --weight_align_factor=1000 --lr=1e-3> ~/iwa/2.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=4 --align_loss='se' --data_transform=True  --kn_init=True --weight_align_factor=1 --lr=1e-3> ~/iwa/3.txt 2>&1 &


#GOOD
nohup python -u cifar10_double.py --gpu=4 --align_loss='ae' --data_transform=True  --kn_init=True --weight_align_factor=100 --lr=1e-3> ~/iwa/4.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=3 --align_loss='ae' --data_transform=True  --kn_init=True --weight_align_factor=100 --lr=1e-3> ~/iwa/4_imbalanced_data.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=2 --align_loss='ae' --data_transform=True  --kn_init=True --weight_align_factor=100 --lr=1e-3> ~/iwa/4_lr_schedule.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=0 --align_loss='ae' --data_transform=True  --kn_init=True --weight_align_factor=100 --lr=1e-3> ~/iwa/4_lr2.txt 2>&1 &

nohup python -u cifar10_double.py --gpu=2 --align_loss='ae' --data_transform=True  --kn_init=True --weight_align_factor=100 --lr=1e-3 --epochs=5> ~/iwa/4_epochs.txt 2>&1 &


nohup python -u cifar10_double.py --gpu=5 --baseline=True --data_transform=True > ~/iwa/4_baseline.txt 2>&1 &
nohup python -u mnist_double.py --gpu=1 --kn_init=True --weight_align_factor=10 --merge_iter=20000 --graphs=True> ~/iwa/mnist_1.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=6 --align_loss='ae' --kn_init=True --weight_align_factor=100 --lr=1e-3> ~/iwa/4_2.txt 2>&1 &
nohup python -u cifar10_double.py --gpu=5 --baseline=True --epochs=300 > ~/iwa/4_baseline2.txt 2>&1 &


nohup python -u cifar10_double.py --gpu=5  --data_transform=True --epochs=5> ~/iwa/4_new.txt 2>&1 &



nohup python -u mnist_double_cnn.py --gpu=5 --kn_init=True --weight_align_factor=10 --merge_iter=2000 --epochs=10> ~/iwa/mnist_cnn_epoch.txt 2>&1 &